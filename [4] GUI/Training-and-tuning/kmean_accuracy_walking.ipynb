{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interessting notes\n",
    "- Walking and running is easily classified by Kmeans\n",
    "- going up and down stairs is harder to classify\n",
    "  - Especially when going down stairs!\n",
    "  - We cannot explain this yet\n",
    "- Overal accuracy is 0.82, but RF is way better for this relativly simple dataset (1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ Imports ------ #\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from util import computeFeatureImportance\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seed and random state to be able to reproduce results\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ Settings ------ #\n",
    "n_clusters = 4\n",
    "train_size = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ Data import ------ #\n",
    "print(\"Importing data...\")\n",
    "x = pd.read_csv(r'Data Gathering and Preprocessing/features_Walking_scaled.csv')\n",
    "print(\"Data imported\")\n",
    "print(f\"Shape of data: {x.shape}\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ shuffling + train, test split ------ #\n",
    "print(\"shuffling data and splitting data into train and test...\")\n",
    "train, test = train_test_split(x, train_size=train_size, shuffle=True)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ x, y split ------ #\n",
    "\n",
    "print(\"Splitting data into x and y...\")\n",
    "le = LabelEncoder()\n",
    "le.fit(train[\"label\"])\n",
    "print(f\"Classes: {le.classes_}\")\n",
    "\n",
    "y_train = le.transform(train[\"label\"])\n",
    "x_train = train.copy()\n",
    "x_train = x_train.drop([\"label\", \"time\", \"ID\"], axis=1)\n",
    "\n",
    "y_test = le.transform(test[\"label\"])\n",
    "x_test = test.copy()\n",
    "x_test = x_test.drop([\"label\", \"time\", \"ID\"], axis=1)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ PCA ------ #\n",
    "\n",
    "print(\"starting PCA...\")\n",
    "pca = PCA(2)\n",
    "df = pca.fit_transform(x_train)\n",
    "df_test = pca.fit_transform(x_test)\n",
    "\n",
    "x_train_pca = np.array(df)\n",
    "x_test_pca = np.array(df_test)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ Training KMeans ------ #\n",
    "\n",
    "print(\"Training KMeans...\")\n",
    "model = KMeans(n_clusters=n_clusters)\n",
    "model.fit(x_train)\n",
    "label = model.labels_\n",
    "print(\"Training done\")\n",
    "\n",
    "pred_y = model.predict(x_test)\n",
    "print(f\"KMeans accuracy: {accuracy_score(y_test, pred_y)}\")\n",
    "\n",
    "model = KMeans(n_clusters=n_clusters)\n",
    "model.fit(df)\n",
    "label = model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ centroid ------ #\n",
    "\n",
    "print(\"Calculating centroids...\")\n",
    "centroids = model.cluster_centers_\n",
    "u_labels = np.unique(label)\n",
    "\n",
    "cdict = {0: 'red', 1: 'blue', 2: 'green', 3: 'yellow', 4: 'brown', 5: 'purple', 6: 'orange', 7: 'pink'}\n",
    "ldict = {}\n",
    "for i in range(len(u_labels)):\n",
    "    ldict[i] = le.classes_[i]\n",
    "    \n",
    "print(\"predicting...\")\n",
    "pred = model.predict(df_test)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plotting model and test data...\")\n",
    "\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "\n",
    "axs[0, 0].title.set_text('Model')\n",
    "for l in u_labels:\n",
    "    ii = np.where(label == l)\n",
    "    axs[0, 0].scatter(x_train_pca[ii, 0], x_train_pca[ii, 1], c=cdict[l], label=ldict[l])\n",
    "# axs[0, 0].scatter(df[:, 0], df[:, 1], c=label)\n",
    "\n",
    "axs[0, 0].scatter(centroids[:,0] , centroids[:,1] , s = 80, c=\"black\", marker='x')\n",
    "\n",
    "# ------ prediction test data ------ #\n",
    "# Make predictions on the test data\n",
    "\n",
    "axs[0, 1].title.set_text('new data points')\n",
    "axs[0, 1].scatter(df_test[:, :1], df_test[:, 1:], c='grey')\n",
    "axs[0, 1].scatter(centroids[:,0] , centroids[:,1] , s = 80, c=\"black\", marker='x')\n",
    "\n",
    "# create second plot which show new points whichout prediction\n",
    "axs[1, 0].title.set_text('New data on model')\n",
    "for l in u_labels:\n",
    "    ii = np.where(label == l)\n",
    "    axs[1, 0].scatter(x_train_pca[ii, 0], x_train_pca[ii, 1], c=cdict[l], label=ldict[l])\n",
    "axs[1, 0].scatter(df_test[:, :1], df_test[:, 1:], c='grey')\n",
    "axs[1, 0].scatter(centroids[:,0] , centroids[:,1] , s = 80, c=\"black\", marker='x')\n",
    "\n",
    "# create third plot which show the predictions of the new points\n",
    "axs[1, 1].title.set_text('result')\n",
    "for l in u_labels:\n",
    "    ii = np.where(label == l)\n",
    "    axs[1, 1].scatter(x_train_pca[ii, 0], x_train_pca[ii, 1], c=cdict[l], label=ldict[l])\n",
    "for l in u_labels:\n",
    "    ii = np.where(pred == l)\n",
    "    axs[1, 1].scatter(x_test_pca[ii, 0], x_test_pca[ii, 1], c=cdict[l])\n",
    "axs[1, 1].scatter(centroids[:,0] , centroids[:,1] , s = 80, c=\"black\", marker='x')\n",
    "plt.show()\n",
    "\n",
    "print(\"plotting model vs actual...\")\n",
    "fig, axs = plt.subplots(2)\n",
    "axs[0].title.set_text('model result')\n",
    "for l in u_labels:\n",
    "    ii = np.where(label == l)\n",
    "    axs[0].scatter(x_train_pca[ii, 0], x_train_pca[ii, 1], c=cdict[l], label=ldict[l])\n",
    "axs[0].scatter(centroids[:,0] , centroids[:,1] , s = 80, c=\"black\", marker='x')\n",
    "\n",
    "axs[1].title.set_text('Actual result')\n",
    "for l in u_labels:\n",
    "    ii = np.where(y_train == l)\n",
    "    axs[1].scatter(x_train_pca[ii, 0], x_train_pca[ii, 1], c=cdict[l], label=ldict[l])\n",
    "axs[1].scatter(centroids[:,0] , centroids[:,1] , s = 80, c=\"black\", marker='x')\n",
    "axs[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=n_clusters)\n",
    "model.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_test_walking = test[test[\"label\"] == \"walking\"]\n",
    "y_test_walking = le.transform(x_test_walking[\"label\"])\n",
    "x_test_walking = x_test_walking.drop([\"label\", \"time\", \"ID\"], axis=1)\n",
    "print(x_test_walking)\n",
    "print(y_test_walking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_running = test[test[\"label\"] == \"running\"]\n",
    "y_test_running = le.transform(x_test_running[\"label\"])\n",
    "x_test_running = x_test_running.drop([\"label\", \"time\", \"ID\"], axis=1)\n",
    "print(x_test_running)\n",
    "print(y_test_running)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_stairs_down = test[test[\"label\"] == \"stairs_down\"]\n",
    "y_test_stairs_down = le.transform(x_test_stairs_down[\"label\"])\n",
    "x_test_stairs_down = x_test_stairs_down.drop([\"label\", \"time\", \"ID\"], axis=1)\n",
    "print(x_test_stairs_down)\n",
    "print(y_test_stairs_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_stairs_up = test[test[\"label\"] == \"stairs_up\"]\n",
    "y_test_stairs_up = le.transform(x_test_stairs_up[\"label\"])\n",
    "x_test_stairs_up = x_test_stairs_up.drop([\"label\", \"time\", \"ID\"], axis=1)\n",
    "print(x_test_stairs_up)\n",
    "print(y_test_stairs_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_walking = model.predict(x_test_walking)\n",
    "print(y_pred_walking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_running = model.predict(x_test_running)\n",
    "print(y_pred_running)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_stairs_down = model.predict(x_test_stairs_down)\n",
    "print(y_pred_stairs_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_stairs_up = model.predict(x_test_stairs_up)\n",
    "print(y_pred_stairs_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_pred_walking, return_counts=True)\n",
    "\n",
    "count_dict_walking = dict(zip(unique, counts))\n",
    "print(\"walking\")\n",
    "print(count_dict_walking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_pred_running, return_counts=True)\n",
    "\n",
    "count_dict_running = dict(zip(unique, counts))\n",
    "print(\"running\")\n",
    "print(count_dict_running)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_pred_stairs_up, return_counts=True)\n",
    "\n",
    "count_dict_stairs_up = dict(zip(unique, counts))\n",
    "print(\"stairs_up\")\n",
    "print(count_dict_stairs_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_pred_stairs_down, return_counts=True)\n",
    "\n",
    "count_dict_stairs_down = dict(zip(unique, counts))\n",
    "print(\"stairs_down\")\n",
    "print(count_dict_stairs_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_dict = {0: \"walking\", 1: \"running\", 3: \"stairs_up\", 2: \"stairs_down\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walking_acc = count_dict_walking[0] / (count_dict_walking[0] + count_dict_walking[2])\n",
    "print(\"walking_acc\")\n",
    "print(walking_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_acc = count_dict_running[1] / (count_dict_running[1])\n",
    "print(\"running_acc\")\n",
    "print(running_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stairs_up_acc = count_dict_stairs_up[3] / (count_dict_stairs_up[2] + count_dict_stairs_up[0] + count_dict_stairs_up[3])\n",
    "print(\"stairs_up_acc\")\n",
    "print(stairs_up_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stairs_down_acc = count_dict_stairs_down[2] / (count_dict_stairs_down[3] + count_dict_stairs_down[2])\n",
    "print(\"stairs_down_acc\")\n",
    "print(stairs_down_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using best case scenario! (walking = 0, running = 1, stairs_up = 3, stairs_down = 2)\n",
    "print(\"Accuracy of kmeans with walking dataset:\")\n",
    "print((walking_acc * len(y_pred_walking) + running_acc * len(y_pred_running) + stairs_up_acc * len(y_pred_stairs_up) + stairs_down_acc * len(y_pred_stairs_down)) / (len(y_pred_walking) + len(y_pred_running) + len(y_pred_stairs_up) + len(y_pred_stairs_down)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Random Forest model...\")\n",
    "rf = RF()\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "y_pred_train = rf.predict(x_train)\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "y_pred_test = rf.predict(x_test)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"rf: {accuracy_train=}, {accuracy_test=}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d7eb8fd305b8d55c736643f9c2b7d5c0b9dd374dd53aaf099dfed1b6cf1d681"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
